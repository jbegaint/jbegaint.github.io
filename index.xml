<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jean Bégaint</title>
    <link>https://jbegaint.fr/</link>
    <description>Recent content on Jean Bégaint</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Dec 2018 00:00:00 +0100</lastBuildDate>
    
	<atom:link href="https://jbegaint.fr/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Deep frame interpolation for video compression</title>
      <link>https://jbegaint.fr/publications/deep-frame-interpolation-for-video-compression/</link>
      <pubDate>Thu, 06 Dec 2018 00:00:00 +0100</pubDate>
      
      <guid>https://jbegaint.fr/publications/deep-frame-interpolation-for-video-compression/</guid>
      <description>Authors Jean Bégaint, Franck Galpin, Philippe Guillotel and Christine Guillemot
Abstract Deep neural networks have been recently proposed to solve video interpolation tasks. Given a past and future frame, such networks can be trained to successfully predict the intermediate frame(s). In the context of video compression, these architectures could be useful as an additional inter-prediction mode. Current inter-prediction methods rely on block-matching techniques to estimate the motion between consecutive frames.</description>
    </item>
    
    <item>
      <title>Region-based models for motion compensation in video compression</title>
      <link>https://jbegaint.fr/publications/region-based-models-for-motion-compensation-in-video-compression/</link>
      <pubDate>Tue, 10 Jul 2018 00:00:00 +0100</pubDate>
      
      <guid>https://jbegaint.fr/publications/region-based-models-for-motion-compensation-in-video-compression/</guid>
      <description>Authors Jean Bégaint, Franck Galpin, Philippe Guillotel and Christine Guillemot
Abstract Video codecs are primarily designed assuming that rigid, block-based, two-dimensional displacements are suitable models to describe the motion taking place in a scene. However, translational models are not sufficient to handle real world motion types such as camera zoom, shake, pan, shearing or changes in aspect ratio. We present here a region-based inter- prediction scheme to compensate such motion.</description>
    </item>
    
    <item>
      <title>Region-Based Prediction for Image Compression in the Cloud</title>
      <link>https://jbegaint.fr/publications/region-based-prediction-for-image-compression-in-the-cloud/</link>
      <pubDate>Fri, 29 Dec 2017 00:00:00 +0100</pubDate>
      
      <guid>https://jbegaint.fr/publications/region-based-prediction-for-image-compression-in-the-cloud/</guid>
      <description>Authors Jean Bégaint, Dominique Thoreau, Philippe Guillotel and Christine Guillemot
Abstract Thanks to the increasing number of images stored in the cloud, external image similarities can be leveraged to efficiently compress images by exploiting inter-images correlations. In this paper, we propose a novel image prediction scheme for cloud storage. Unlike current state-of-the-art methods, we use a semi-local approach to exploit inter-image correlation. The reference image is first segmented into multiple planar regions determined from matched local features and super-pixels.</description>
    </item>
    
    <item>
      <title>Towards novel inter-prediction methods for image and video compression</title>
      <link>https://jbegaint.fr/projects/phd-thesis/</link>
      <pubDate>Sun, 26 Nov 2017 12:27:24 +0100</pubDate>
      
      <guid>https://jbegaint.fr/projects/phd-thesis/</guid>
      <description> This thesis aims at exploring novel approaches for improving current inter-prediction methods. Such methods leverage redundancies between similar frames, and were originally developed in the context of video compression. Applications such as images set compression (photo albums, cloud databases) and video compression were considered. The last part of the thesis focuses on deep learning approaches for inter-prediction.
Related publications  Deep frame interpolation for video compression (submitted) Region-based models for motion compensation in video compression (PCS 2018) Region Based Prediction for Image Compression in the Cloud (TIP 2017) Locally-weighted template-matching based prediction for … (DCC 2016)  Related Patents  3 undisclosed filings  </description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://jbegaint.fr/index/</link>
      <pubDate>Sat, 25 Nov 2017 19:01:10 +0100</pubDate>
      
      <guid>https://jbegaint.fr/index/</guid>
      <description>Currently a post-doctoral researcher at the Technicolor AI Lab in Palo Alto, I previously received a PhD in signal processing while working at Technicolor and INRIA. My PhD thesis was focused on new solutions for image and video compression applications, mainly using computer vision and deep learning techniques.
My current research interests include image/video compression, image processing, computer vision, and machine learning.</description>
    </item>
    
    <item>
      <title>Locally-weighted template-matching based prediction for cloud-based image compression</title>
      <link>https://jbegaint.fr/publications/lle-tm-image-compression-cloud/</link>
      <pubDate>Mon, 19 Dec 2016 00:00:00 +0100</pubDate>
      
      <guid>https://jbegaint.fr/publications/lle-tm-image-compression-cloud/</guid>
      <description>Authors Jean Bégaint, Dominique Thoreau, Philippe Guillotel and Mehmet Türkan
Abstract Thanks to the increasing number of images stored in the cloud, external image redundancies can be leveraged to efficiently compress images by exploiting inter-images correlations. In this paper, we propose a novel cloud-based image coding scheme. Unlike current state-of-the-art systems, our method relies on a data dimensionality reduction technique. A global compensation is associated to a locally-weighted template matching compensation method to predict a reference frame, to be then differential-coded with classic video coding tools.</description>
    </item>
    
  </channel>
</rss>